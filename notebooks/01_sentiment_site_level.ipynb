{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: 18\n",
      "fail: ['Cincinnati', 'Columbus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import data\n",
    "import joblib\n",
    "from matplotlib.gridspec import GridSpec\n",
    "files_dict = data.load_files_dict_single_site()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data for single-site analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'Atlanta'\n",
    "# site = 'Columbus'\n",
    "# site = 'WashingtonDC'\n",
    "df = files_dict[site]\n",
    "qs, responses_df, themes_df = data.split_single_site_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sentiment\n",
    "Note: this uses a lot of API calls (num questions * num responses), maybe around 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = '''### You are given a question and a response. Rate the sentiment/supportiveness of the response on a scale of 1 to 5, where 1 is very negative and 5 is very positive. ###\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Response: {response}\n",
    "\n",
    "Rating (1-5):'''\n",
    "\n",
    "llm = imodelsx.llm.get_llm('gpt-4', repeat_delay=None)\n",
    "\n",
    "num_questions = len(qs)\n",
    "sentiments = defaultdict(list)\n",
    "for question_num in tqdm(range(num_questions), position=0):\n",
    "    question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "        question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "\n",
    "    for response_num in tqdm(range(len(responses)), position=1):\n",
    "        response = responses.values[response_num]\n",
    "\n",
    "        if pd.isna(response):\n",
    "            sentiments[question_num].append(np.nan)\n",
    "        else:\n",
    "            prompt = sentiment_prompt.format(\n",
    "                question=question, response=response)\n",
    "            ans = llm(prompt)\n",
    "            sentiments[question_num].append(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.DataFrame([(key, var) for (key, L) in sentiments.items() for var in L],\n",
    "                       columns=['Question', 'Value'])\n",
    "\n",
    "# round  values\n",
    "sent_df['Value'] = sent_df['Value'].astype(float).round()\n",
    "value_maps = {\n",
    "    1: 'Very Negative',\n",
    "    2: 'Negative',\n",
    "    3: 'Neutral',\n",
    "    4: 'Positive',\n",
    "    5: 'Very Positive',\n",
    "}\n",
    "sent_df['Value'] = sent_df['Value'].map(value_maps.get)\n",
    "sent_df['Value'] = sent_df['Value'].fillna('No response')\n",
    "\n",
    "sent_df = sent_df.groupby(['Question', 'Value']).size().unstack(fill_value=0)\n",
    "levels = ['Very Negative', 'Negative', 'Neutral',\n",
    "          'No response', 'Positive', 'Very Positive']\n",
    "sent_df = sent_df.reindex(levels, axis=1)\n",
    "joblib.dump(sent_df, join(data.PROCESSED_DIR, f'sent_df_{site}.pkl'))\n",
    "\n",
    "# make plot\n",
    "sent_df = sent_df.sort_values(by=levels, ascending=False)\n",
    "colors = sns.diverging_palette(20, 220, n=6).as_hex()\n",
    "colors = colors[:2] + ['#ddd', '#eee'] + colors[-2:]\n",
    "sent_df.plot(kind='barh', stacked=True, figsize=(5, 10), color=colors)\n",
    "\n",
    "plt.yticks(range(46), labels=df['Domain'].values[sent_df.index.values])\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.1), loc='center', ncol=3, title='Sentiment')\n",
    "plt.xlabel('Answer count')\n",
    "plt.ylabel('Question number and domain')\n",
    "plt.title(site)\n",
    "plt.savefig(f'../figs/eda/sentiment_example_{site}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate sentiment plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfs = []\n",
    "sites = ['Atlanta', 'Columbus', 'WashingtonDC']\n",
    "for site in sites:\n",
    "    sent_df = joblib.load(join(data.PROCESSED_DIR, f'sent_df_{site}.pkl'))\n",
    "    # sent_df = sent_df.sort_values(by=levels, ascending=False)\n",
    "    sent_dfs.append(sent_df)\n",
    "\n",
    "sum_df = pd.concat(sent_dfs).groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "sum_df = sum_df.sort_values(by=levels, ascending=False)\n",
    "sum_index_sorted = sum_df.index\n",
    "colors = sns.diverging_palette(20, 220, n=6).as_hex()\n",
    "colors = colors[:2] + ['#ddd', '#eee'] + colors[-2:]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "gs = GridSpec(1, 4, width_ratios=[2, 1, 1, 1], wspace=0.025)\n",
    "\n",
    "\n",
    "# first plot\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "sum_df.plot(kind='barh', stacked=True, color=colors, ax=ax1, legend=False)\n",
    "plt.xlim(0, sum_df.sum(axis=1).max())\n",
    "plt.yticks(range(46),\n",
    "           labels=[f'{len(sent_df) - i}. {v}' for i, v in enumerate(\n",
    "               df['Domain'].values[sent_df.index.values])])\n",
    "fig.legend(bbox_to_anchor=(0.5, 0.95), loc='center', ncol=3, title='Sentiment')\n",
    "plt.xlabel('Answer count')\n",
    "plt.title('All sites', fontweight='bold')\n",
    "plt.ylabel('Question number and domain')\n",
    "\n",
    "for i, site in enumerate(sites):\n",
    "    ax = fig.add_subplot(gs[i+1])\n",
    "    sent_df = sent_dfs[i]\n",
    "    sent_df = sent_df.reindex(sum_index_sorted)\n",
    "    sent_df.plot(kind='barh', stacked=True, color=colors, ax=ax, legend=False)\n",
    "    plt.xlim(0, sent_df.sum(axis=1).max())\n",
    "    plt.yticks([])\n",
    "    plt.ylabel('')\n",
    "    plt.title(data.RENAME_SITE_DICT.get(site, site))\n",
    "plt.savefig(f'../figs/sentiment_agg.pdf', bbox_inches='tight')\n",
    "plt.savefig(f'../figs/sentiment_agg.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no limit display\n",
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    d = df.iloc[sum_index_sorted][::-1][['Domain', 'Subcategory']]\n",
    "    d['Question order'] = d.index\n",
    "    d.insert(loc=0, column='Question number', value=np.arange(1, len(d) + 1))\n",
    "    # display(d)\n",
    "    d.to_csv('../figs/question_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human annotation\n",
    "- filter 10 questions that have many themes (these tend to be more interesting)\n",
    "- pick 10 questions, 10 answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select questions\n",
    "def get_num_themes(df):\n",
    "    num_themes_list = []\n",
    "    for question_num in range(len(df)):\n",
    "        question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "            question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "        num_themes_list.append(len(theme_dict))\n",
    "    return np.array(num_themes_list)\n",
    "    # df['num_themes'] = num_themes_list\n",
    "    # return df\n",
    "\n",
    "\n",
    "num_themes = np.zeros(46)\n",
    "SITES = ['Atlanta', 'Columbus', 'WashingtonDC']\n",
    "for site in sites:\n",
    "    df = files_dict[site]\n",
    "    num_themes += get_num_themes(df)\n",
    "idx = pd.Series(num_themes).sort_values(ascending=False)\n",
    "questions_selected = idx.index[:10]\n",
    "\n",
    "# save these questions\n",
    "pd.Series(questions_selected).to_csv(\n",
    "    '../figs/human/sentiment_questions_selected.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 10 random answers for each question\n",
    "resps_dict = defaultdict(list)\n",
    "for question_num in questions_selected:\n",
    "    for site in sites:\n",
    "        df = files_dict[site]\n",
    "        question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "            question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "        resps_dict[question_num] += list(responses)\n",
    "assert np.all(np.array(list(len(v) for v in resps_dict.values())) == 33)\n",
    "\n",
    "\n",
    "# randomly select 10 non-nan responses for each question and record their indices\n",
    "rng = np.random.default_rng(13)\n",
    "resps_idx_selected = defaultdict(list)\n",
    "resps_selected = {}\n",
    "for question_num in questions_selected:\n",
    "    resps = resps_dict[question_num]\n",
    "    indices = np.arange(33)[~pd.isna(resps)]\n",
    "    indices_selected = rng.choice(\n",
    "        indices, size=10, replace=False).tolist()\n",
    "    resps_idx_selected[question_num] = indices_selected\n",
    "    resps_selected[question_num] = [resps[i] for i in indices_selected]\n",
    "\n",
    "# put into a big defaultdict\n",
    "dd = defaultdict(list)\n",
    "for question_num in questions_selected:\n",
    "    for i, resp in enumerate(resps_selected[question_num]):\n",
    "        dd['Question number'].append(question_num)\n",
    "        dd['Response number'].append(resps_idx_selected[question_num][i])\n",
    "\n",
    "        dd['Question'].append(qs[question_num])\n",
    "        dd['Response'].append(resp)\n",
    "\n",
    "# dump\n",
    "with open('../figs/human/sentiment_idx_selected.json', 'w') as f:\n",
    "    json.dump(resps_idx_selected, f, indent=4)\n",
    "ddf = pd.DataFrame.from_dict(dd)\n",
    "ddf.to_csv('../figs/human/sentiment_template.csv', index=False)\n",
    "ddf.to_pickle('../figs/human/sentiment_template.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
