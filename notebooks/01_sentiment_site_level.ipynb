{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: 18\n",
      "fail: ['Cincinnati', 'Columbus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import data\n",
    "import joblib\n",
    "from matplotlib.gridspec import GridSpec\n",
    "files_dict = data.load_files_dict_single_site()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data for single-site analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = 'meta-llama/Llama-2-7b-hf'\n",
    "# checkpoint = 'gpt-4'  # gpt-35-turbo\n",
    "# checkpoint = 'gpt-35-turbo'\n",
    "\n",
    "# site = 'Atlanta'\n",
    "# site = 'Columbus'\n",
    "site = 'WashingtonDC'\n",
    "df = files_dict[site]\n",
    "qs, responses_df, themes_df = data.split_single_site_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sentiment\n",
    "Note: this uses a lot of API calls (num questions * num responses), maybe around 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = '''### You are given a question and a response. Rate the sentiment/supportiveness of the response on a scale of 1 to 5, where 1 is very negative and 5 is very positive. ###\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Response: {response}\n",
    "\n",
    "Rating (1-5):'''\n",
    "\n",
    "llm = imodelsx.llm.get_llm('gpt-4', repeat_delay=None)\n",
    "\n",
    "num_questions = len(qs)\n",
    "sentiments = defaultdict(list)\n",
    "for question_num in tqdm(range(num_questions), position=0):\n",
    "    question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "        question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "\n",
    "    for response_num in tqdm(range(len(responses)), position=1):\n",
    "        response = responses.values[response_num]\n",
    "\n",
    "        if pd.isna(response):\n",
    "            sentiments[question_num].append(np.nan)\n",
    "        else:\n",
    "            prompt = sentiment_prompt.format(\n",
    "                question=question, response=response)\n",
    "            ans = llm(prompt)\n",
    "            sentiments[question_num].append(ans)\n",
    "pd.DataFrame(sentiments).T.to_pickle(\n",
    "    join(data.PROCESSED_DIR, f'sentiments_df_{site}_{checkpoint.split(\"/\")[-1]}.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.DataFrame([(key, var) for (key, L) in sentiments.items() for var in L],\n",
    "                       columns=['Question', 'Value'])\n",
    "\n",
    "# round  values\n",
    "sent_df['Value'] = sent_df['Value'].astype(float).round()\n",
    "value_maps = {\n",
    "    1: 'Very Negative',\n",
    "    2: 'Negative',\n",
    "    3: 'Neutral',\n",
    "    4: 'Positive',\n",
    "    5: 'Very Positive',\n",
    "}\n",
    "sent_df['Value'] = sent_df['Value'].map(value_maps.get)\n",
    "sent_df['Value'] = sent_df['Value'].fillna('No response')\n",
    "\n",
    "sent_df = sent_df.groupby(['Question', 'Value']).size().unstack(fill_value=0)\n",
    "levels = ['Very Negative', 'Negative', 'Neutral',\n",
    "          'No response', 'Positive', 'Very Positive']\n",
    "sent_df = sent_df.reindex(levels, axis=1)\n",
    "joblib.dump(sent_df, join(data.PROCESSED_DIR, f'sent_df_{site}.pkl'))\n",
    "\n",
    "# make plot\n",
    "sent_df = sent_df.sort_values(by=levels, ascending=False)\n",
    "colors = sns.diverging_palette(20, 220, n=6).as_hex()\n",
    "colors = colors[:2] + ['#ddd', '#eee'] + colors[-2:]\n",
    "sent_df.plot(kind='barh', stacked=True, figsize=(5, 10), color=colors)\n",
    "\n",
    "plt.yticks(range(46), labels=df['Domain'].values[sent_df.index.values])\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.1), loc='center', ncol=3, title='Sentiment')\n",
    "plt.xlabel('Answer count')\n",
    "plt.ylabel('Question number and domain')\n",
    "plt.title(site)\n",
    "plt.savefig(f'../figs/eda/sentiment_example_{site}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate sentiment plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfs = []\n",
    "sites = ['Atlanta', 'Columbus', 'WashingtonDC']\n",
    "for site in sites:\n",
    "    sent_df = joblib.load(join(data.PROCESSED_DIR, f'sent_df_{site}.pkl'))\n",
    "    # sent_df = sent_df.sort_values(by=levels, ascending=False)\n",
    "    sent_dfs.append(sent_df)\n",
    "\n",
    "sum_df = pd.concat(sent_dfs).groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "sum_df = sum_df.sort_values(by=levels, ascending=False)\n",
    "sum_index_sorted = sum_df.index\n",
    "colors = sns.diverging_palette(20, 220, n=6).as_hex()\n",
    "colors = colors[:2] + ['#ddd', '#eee'] + colors[-2:]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "gs = GridSpec(1, 4, width_ratios=[2, 1, 1, 1], wspace=0.025)\n",
    "\n",
    "\n",
    "# first plot\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "sum_df.plot(kind='barh', stacked=True, color=colors, ax=ax1, legend=False)\n",
    "plt.xlim(0, sum_df.sum(axis=1).max())\n",
    "plt.yticks(range(46),\n",
    "           labels=[f'{len(sent_df) - i}. {v}' for i, v in enumerate(\n",
    "               df['Domain'].values[sent_df.index.values])])\n",
    "fig.legend(bbox_to_anchor=(0.5, 0.95), loc='center', ncol=3, title='Sentiment')\n",
    "plt.xlabel('Answer count')\n",
    "plt.title('All sites', fontweight='bold')\n",
    "plt.ylabel('Question number and domain')\n",
    "\n",
    "for i, site in enumerate(sites):\n",
    "    ax = fig.add_subplot(gs[i+1])\n",
    "    sent_df = sent_dfs[i]\n",
    "    sent_df = sent_df.reindex(sum_index_sorted)\n",
    "    sent_df.plot(kind='barh', stacked=True, color=colors, ax=ax, legend=False)\n",
    "    plt.xlim(0, sent_df.sum(axis=1).max())\n",
    "    plt.yticks([])\n",
    "    plt.ylabel('')\n",
    "    plt.title(data.RENAME_SITE_DICT.get(site, site))\n",
    "plt.savefig(f'../figs/sentiment_agg.pdf', bbox_inches='tight')\n",
    "plt.savefig(f'../figs/sentiment_agg.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no limit display\n",
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    d = df.iloc[sum_index_sorted][::-1][['Domain', 'Subcategory']]\n",
    "    d['Question order'] = d.index\n",
    "    d.insert(loc=0, column='Question number', value=np.arange(1, len(d) + 1))\n",
    "    # display(d)\n",
    "    d.to_csv('../figs/question_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_index_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original function filter 10 questions that have many themes (these tend to be more interesting)\n",
    "# # select questions\n",
    "# def get_num_themes(df):\n",
    "#     num_themes_list = []\n",
    "#     for question_num in range(len(df)):\n",
    "#         question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "#             question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "#         num_themes_list.append(len(theme_dict))\n",
    "#     return np.array(num_themes_list)\n",
    "#     # df['num_themes'] = num_themes_list\n",
    "#     # return df\n",
    "\n",
    "\n",
    "# num_themes = np.zeros(46)\n",
    "# SITES = ['Atlanta', 'Columbus', 'WashingtonDC']\n",
    "# for site in sites:\n",
    "#     df = files_dict[site]\n",
    "#     num_themes += get_num_themes(df)\n",
    "# idx = pd.Series(num_themes).sort_values(ascending=False)\n",
    "# questions_selected = idx.index[:10]\n",
    "\n",
    "# instead pick 3 most positive, 3 middle, and 3 most negative\n",
    "mid = 46 // 2\n",
    "sorted_qs = list(sum_index_sorted)\n",
    "questions_selected = sorted_qs[:3] + sorted_qs[mid-1:mid+2] + sorted_qs[-3:]\n",
    "\n",
    "# save these questions\n",
    "pd.Series(questions_selected).to_csv(\n",
    "    '../figs/human/sentiment_questions_selected.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select random answers to questions (up to 15 per question)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in responses from all sites\n",
    "resps_dict = defaultdict(list)\n",
    "for question_num in questions_selected:\n",
    "    for site in ['Atlanta', 'Columbus', 'WashingtonDC']:\n",
    "        df = files_dict[site]\n",
    "        question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "            question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "        resps_dict[question_num] += list(responses)\n",
    "assert np.all(np.array(list(len(v) for v in resps_dict.values())) == 33)\n",
    "\n",
    "\n",
    "# randomly select up to 15 non-nan responses for each question and record their indices (less if there are fewer than 15)\n",
    "rng = np.random.default_rng(13)\n",
    "resps_idx_selected = defaultdict(list)\n",
    "resps_selected = {}\n",
    "for question_num in questions_selected:\n",
    "    resps = resps_dict[question_num]\n",
    "    indices = np.arange(33)[~pd.isna(resps)]\n",
    "    indices_selected = rng.choice(\n",
    "        indices, size=min(len(indices), 15), replace=False).tolist()\n",
    "    resps_idx_selected[question_num] = indices_selected\n",
    "    resps_selected[question_num] = [resps[i] for i in indices_selected]\n",
    "\n",
    "# put into a big defaultdict\n",
    "dd = defaultdict(list)\n",
    "for question_num in questions_selected:\n",
    "    for i, resp in enumerate(resps_selected[question_num]):\n",
    "        dd['Question number'].append(question_num)\n",
    "        dd['Response number'].append(resps_idx_selected[question_num][i])\n",
    "\n",
    "        dd['Question'].append(qs[question_num])\n",
    "        dd['Response'].append(resp)\n",
    "\n",
    "# dump\n",
    "with open('../figs/human/sentiment_idx_selected.json', 'w') as f:\n",
    "    json.dump(resps_idx_selected, f, indent=4)\n",
    "ddf = pd.DataFrame.from_dict(dd)\n",
    "ddf.to_csv('../figs/human/sentiment_template.csv', index=False)\n",
    "ddf.to_pickle('../figs/human/sentiment_template.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pd.read_pickle('../figs/human/sentiment_template.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hum1 = pd.read_csv('../figs/human/collected/sentiment_human1.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_whitespace(s):\n",
    "    return ''.join(s.split())\n",
    "\n",
    "\n",
    "# check for matching index\n",
    "assert np.all(hum1['Response number'].astype(str).apply(remove_all_whitespace).values ==\n",
    "              template['Response number'].astype(str).apply(remove_all_whitespace).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "template['hum1'] = hum1['Rating'].values.astype(int)\n",
    "# check that values are in range 1-5\n",
    "assert np.all(template['hum1'].values >= 1)\n",
    "assert np.all(template['hum1'].values <= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dfs = []\n",
    "for checkpoint in ['gpt-4']:\n",
    "    sites = ['Atlanta', 'Columbus', 'WashingtonDC']\n",
    "    for site in sites:\n",
    "        sent_df = joblib.load(join(\n",
    "            data.PROCESSED_DIR, f'sentiments_df_{site}_{checkpoint.split(\"/\")[-1]}.pkl'))\n",
    "        sent_dfs.append(sent_df)\n",
    "\n",
    "sent_dfs[0].columns = np.arange(0, 11)\n",
    "sent_dfs[1].columns = np.arange(11, 22)\n",
    "sent_dfs[2].columns = np.arange(22, 33)\n",
    "sent_llm_full = pd.concat(sent_dfs, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "template[checkpoint] = template.apply(\n",
    "    lambda row: sent_llm_full[row['Question number'], row['Response number']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num annots 105\n"
     ]
    }
   ],
   "source": [
    "notna = ~pd.isna(template['gpt-4'])  # make sure to apply this across all llms\n",
    "print('num annots', notna.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr 0.6662705790585307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.6714471353248148, pvalue=4.539363678831263e-15)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "x = template['hum1'][notna]\n",
    "y = template['gpt-4'][notna].astype(float)\n",
    "print('corr', np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "# compute rank correlation\n",
    "spearmanr(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
